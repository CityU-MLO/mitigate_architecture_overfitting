# Towards Mitigating Architecture Overfitting on Distilled Datasets
Author: *Xuyang Zhong, Chen Liu*

This paper is accepted by *IEEE Transactions on Neural Networks and Learning Systems (TNNLS)*.

## Requirements

PyTorch, Torchvision, Numpy, Kornia

## Distilled Data and Checkpoints of Teacher Models

We provide the distilled data of FRePo and MTT and the checkpoints of trained teacher models at [Google Drive]().

## Run Our Code
Baseline
```
python train.py --exp_name test --no_log --seed 2333 --gpu 0 --data_name cifar10 --data_dir [DATA PATH] --distill_data_dir ./distilled_data/cifar10_10_frepo --tau 0.3 --model_name resnetdp --norm batchnorm --max_epoch 1000 --lr 5e-4 --batch_size 100 --optim adam --save_freq 100 --aug_mode 1 --scheduler default  --zca
```

w/o DP&KD
```
python train.py --exp_name test --no_log --seed 2333 --gpu 0 --data_name cifar10 --data_dir [DATA PATH] --distill_data_dir ./distilled_data/cifar10_10_frepo --tau 0.3 --model_name resnetdp --norm batchnorm --max_epoch 1000 --lr 5e-5 --batch_size 100 --optim lion --save_freq 100 --aug_mode 2 --scheduler improved --zca
```

w/o DP
```
python train.py --exp_name test --no_log --seed 2333 --gpu 0 --data_name cifar10 --data_dir [DATA PATH] --distill_data_dir ./distilled_data/cifar10_10_frepo --tau 0.3 --model_name resnetdp --norm batchnorm --max_epoch 1000 --lr 5e-5 --batch_size 100 --optim lion --save_freq 100 --aug_mode 2 --scheduler improved --kd --teacher_model_name convnetfrepo --teacher_ckpt_path ./snapshots/cifar10_10_frepo_convnet/checkpoint_best.pth --zca
```

w/o KD
```
python train.py --exp_name test --no_log --seed 2333 --gpu 0 --data_name cifar10 --data_dir [DATA PATH] --distill_data_dir ./distilled_data/cifar10_10_frepo --tau 0.3 --model_name resnetdp --norm batchnorm --max_epoch 4000 --lr 5e-5 --batch_size 100 --optim lion --save_freq 100 --aug_mode 2 --scheduler improved  --strategy more2less --zca
```

Full
```
python train.py --exp_name test --no_log --seed 2333 --gpu 0 --data_name cifar10 --data_dir [DATA PATH] --distill_data_dir ./distilled_data/cifar10_10_frepo --tau 0.3 --model_name resnetdp --norm batchnorm --max_epoch 4000 --lr 5e-5 --batch_size 100 --optim lion --save_freq 100 --aug_mode 2 --scheduler improved --kd --teacher_model_name convnetfrepo --teacher_ckpt_path ./snapshots/cifar10_10_frepo_convnet/checkpoint_best.pth --strategy more2less --zca
```

The code shown above is to use our method to train ResNet18 on distilled data generated by FRePo, CIFAR10, IPC=10. The teacher model is ConvNet of FRePo version. If you want to run our code with other setting, please refer to implementation details in our paper.

## Acknowledgement

Part of our codes are referred to [GeorgeCazenavette/mtt-distillation: Official code for our CVPR '22 paper "Dataset Distillation by Matching Training Trajectories" (github.com)](https://github.com/GeorgeCazenavette/mtt-distillation)
